{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook aims to build a Artificial Neural Network (NN) in order to beat a Ordinary Least Squares Regression (OLS).\n",
    "\n",
    "The comparison variable shall be the Mean Average Percentage Error (MAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from datetime import datetime\n",
    "from MLP import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = '<NA>'\n",
    "\n",
    "df = pd.read_csv(r'../data_file/selected_data.csv')\n",
    "df = df.replace(na, np.nan).drop(columns = [df.columns[0]])\n",
    "\n",
    "obj_type, rooms, surface, zip_code_2_digits, zip_code_3_digits, canton, year_built, year_renovated, distance_to_station, lon, lat, price_square_metres, price = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- frame_to_numeric aims to force each string-formated value to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_numeric(frame):\n",
    "    \"\"\"transforms every value of a data frame to numeric if possible\"\"\"\n",
    "    for column in frame.columns:\n",
    "        try:\n",
    "            frame.loc[:, column] = pd.to_numeric(frame.loc[:, column])\n",
    "        except:\n",
    "            continue #nothing toDo here\n",
    "    return frame\n",
    "\n",
    "df = frame_to_numeric(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add_nearest_rooms_by_surface & add_surface_mean_by_nearest_rooms aims to fill missing surface and rooms values in order to have a larger dataset to train the LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rooms_surface_mean(df):\n",
    "    df = frame_to_numeric(df.loc[:, [rooms, surface]].dropna())\n",
    "    return df.groupby(rooms).mean()\n",
    "\n",
    "def add_rooms(row, df_rooms_mean):\n",
    "    return df_rooms_mean.loc[row[rooms]]\n",
    "\n",
    "def add_nearest_rooms_by_surface(df):\n",
    "    \"\"\"completes the dataframe rooms by the nearest neighbour based on the surface mean distance\n",
    "    and the surface of the missing rooms objects\"\"\"\n",
    "    df = df.reset_index(drop = True)\n",
    "    df_rooms_mean = rooms_surface_mean(df)\n",
    "    df_rooms_missing = df[df.loc[:, rooms].isna()].loc[:, [surface]]\n",
    "    dist = cdist(df_rooms_missing, df_rooms_mean) #computes the distance between each pair of surface\n",
    "    idx = np.argsort(dist) #gets sorted index (most left = lowest distance index)\n",
    "    rooms_class = idx[:,0] #gets the room class (index)\n",
    "    df_rooms_missing.loc[:, rooms] = rooms_class\n",
    "    df_rooms_mean = df_rooms_mean.reset_index()\n",
    "    df_rooms_missing.loc[:, rooms] = df_rooms_missing.apply(lambda row: add_rooms(row, df_rooms_mean), axis = 1)\n",
    "    df.loc[df_rooms_missing.index, rooms] = df_rooms_missing.loc[:, rooms] #appends the missing rooms to the real data-frame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_surface(row, df_rooms_mean):\n",
    "    return df_rooms_mean.loc[row[surface]]\n",
    "\n",
    "def add_surface_mean_by_nearest_rooms(df):\n",
    "    \"\"\"completes the dataframe surface by the nearest neighbour surface mean based on the room distance\n",
    "    of the missing surface objects\"\"\"\n",
    "    df = df.reset_index(drop = True)\n",
    "    df_rooms_mean = rooms_surface_mean(df).reset_index()\n",
    "    df_surface_missing = df[df.loc[:, surface].isna()].loc[:, [rooms]]\n",
    "    dist = cdist(df_surface_missing, df_rooms_mean.loc[:, [rooms]]) #computes the distance between each pair of rooms\n",
    "    idx = np.argsort(dist) #gets sorted index (most left = lowest distance index)\n",
    "    surface_class = idx[:,0] #gets the surface class (index)\n",
    "    df_surface_missing.loc[:, surface] = surface_class\n",
    "    df_surface_missing.loc[:, surface] = df_surface_missing.apply(lambda row: add_surface(row, df_rooms_mean), axis = 1)\n",
    "    df.loc[df_surface_missing.index, surface] = df_surface_missing.loc[:, surface]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- handle_missing_numeric_feature completes missing values of a dataframe with an additional feature which has a value 1 if the value was not missing and 0 if it was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_numeric_feature(df, feature, na):\n",
    "    \"\"\"this function completes the missing vlaues of a data-frame with the median of the given numeric feature\n",
    "    it adds a new column `feature`+'_'+`na` at the end of the feature index,\n",
    "    which is going to be '1' if the value of the data object is missing and '0' otherwise \n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    na_index = pd.Index(df_copy.columns).get_loc(feature) + 1\n",
    "    column = df_copy.loc[:, feature]\n",
    "    column = column.replace(np.nan, na, regex = True)\n",
    "    artificial_column = [1. if x == na else 0. for x in column] #comprehensions\n",
    "    df.insert(na_index, feature+'_'+na, artificial_column)\n",
    "    \n",
    "    na_indexes = column[column == na].index\n",
    "    feature_median = df_copy.loc[:, feature].median()\n",
    "    df.loc[na_indexes, feature] = feature_median\n",
    "    return df\n",
    "\n",
    "def missing_numerical_features_controller(df, features, na):\n",
    "    \"\"\"this function just calls the :func:`handle_missing_numeric_feature` for each given feature\"\"\"\n",
    "    for feature in features:\n",
    "        df = handle_missing_numeric_feature(df, feature, na)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one_hot_encoding transformes catecorical features to numeric with the one hot encoding method because the NN model just works with numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, na, feature_name, new_encoding = False):\n",
    "    \"\"\"performs a complete one-hit encoding on the specified feature of the dataframe\n",
    "    adds a the prefix '_' to each unique encoding class\n",
    "    set `new_encoding` = True if the data are not in the same order as before!!! otherwise it returns a false encoding\n",
    "    separates automatically all missing values as it's own category named: feature_name+'_'+na\n",
    "    returns: \n",
    "    -encoded data-frame\n",
    "    -categories of the variable as an array\n",
    "    \"\"\"\n",
    "    enc = OneHotEncoder()\n",
    "    df = df.copy()\n",
    "    delimiter = feature_name + '_'\n",
    "    na_delimiter = '_' + na\n",
    "    enc_dir = './enc'\n",
    "    cat_dir = './cat'\n",
    "    enc_path = enc_dir+'/'+feature_name+'.npz'\n",
    "    cat_path = cat_dir+'/categories.pkl'\n",
    "    encoding = False\n",
    "    sparse_matrix = None\n",
    "    category = None\n",
    "    all_cat = {}\n",
    "    \n",
    "    #creates directories if not exists\n",
    "    if not os.path.exists(enc_dir):\n",
    "        encoding = True\n",
    "        os.makedirs(enc_dir)\n",
    "    if not os.path.exists(cat_dir):\n",
    "        encoding = True\n",
    "        os.makedirs(cat_dir)\n",
    "        \n",
    "    #gets the dictionary with all categories\n",
    "    try:\n",
    "        all_cat = load_obj(cat_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #deletes files if they exists and new_encoding is True\n",
    "    if new_encoding:\n",
    "        encoding = True\n",
    "        try:\n",
    "            os.remove(enc_path)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del all_cat[feature_name]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #tries to get sparse matrix & head if new_encoding == False\n",
    "    if not encoding:\n",
    "        try:\n",
    "            sparse_matrix = scipy.sparse.load_npz(enc_path)\n",
    "            #check if size of sparse_matrix matches size of the df\n",
    "            if sparse_matrix.shape[0] != df.shape[0]:\n",
    "                sparse_matrix = None\n",
    "            category = all_cat.get(feature_name)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #perform actual encoding if necessary\n",
    "    if (sparse_matrix is None) or (category is None):\n",
    "        if df.loc[:, [feature_name]].isnull().values.any():\n",
    "            df.loc[:, feature_name] = df.loc[:, feature_name].replace(np.nan, feature_name + na_delimiter, regex = True)\n",
    "        selected_frame = delimiter + df.loc[:, feature_name].astype(str).to_frame()\n",
    "        sparse_matrix = enc.fit_transform(selected_frame)\n",
    "        category = enc.categories_[0]\n",
    "        all_cat[feature_name] = category\n",
    "        scipy.sparse.save_npz(enc_path, sparse_matrix)\n",
    "        save_obj(all_cat, cat_path)\n",
    "    \n",
    "    #add encoded matrix to the df\n",
    "    encoded_array = sparse_matrix.toarray()\n",
    "    df_enc = pd.DataFrame(data = encoded_array, columns = category)\n",
    "    category_sorted = np.sort(category)\n",
    "    df_enc = df_enc[category_sorted]\n",
    "    df = df.drop(columns = [feature_name])\n",
    "    df[category_sorted] = df_enc\n",
    "    return df, category_sorted\n",
    "\n",
    "def save_obj(obj, path):\n",
    "    if len(path) < 5:\n",
    "        path = path + '.pkl'\n",
    "    elif path[-4:] != '.pkl':\n",
    "        path = path + '.pkl'\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(path):\n",
    "    if len(path) < 5:\n",
    "        path = path + '.pkl'\n",
    "    elif path[-4:] != '.pkl':\n",
    "        path = path + '.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_prepared_df(df, na, target_variable = None, categorical_features = [], numerical_features = [], additional_features = [], new_encoding = False):\n",
    "    \"\"\"returns the data frame with the specified encoded features and the corresponding generated categories\n",
    "    set `new_encoding` = True if the data are not in the same order as before!!! otherwise it returns a false encoding\"\"\"\n",
    "    df_selected = df.loc[:, (numerical_features + categorical_features + additional_features)]\n",
    "    categories = {}\n",
    "    df_selected = normalize_df(df_selected, numerical_features)\n",
    "    for feature in categorical_features:\n",
    "        df_selected, categories[feature] = one_hot_encoding(df_selected, na, feature, new_encoding)\n",
    "    if target_variable is not None:\n",
    "        df_selected[target_variable] = df.loc[:, target_variable]\n",
    "    return df_selected, categories\n",
    "\n",
    "def normalize_df(df, features):\n",
    "    \"\"\"normalizes the given numerical sample\"\"\"\n",
    "    #df[features] = StandardScaler().fit_transform(df.loc[:, features])\n",
    "    X = df.loc[:, features].to_numpy()\n",
    "    X -= np.mean(X, axis = 0)\n",
    "    X /= np.std(X, axis = 0)\n",
    "    df[features] = X\n",
    "    return df\n",
    "\n",
    "def mape(y_true, y_pred): \n",
    "    \"\"\"calculates the mean absolute percentage error (MAPE) of a continuous predicted variable\"\"\"\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def load_mlp_res(path):\n",
    "    if not os.path.exists(path):\n",
    "        df_mlp = pd.DataFrame(columns = ['features', 'layers', 'learning_rate', 'alpha', 'batch_size', 'residuals', 'MAPE'])\n",
    "    else:\n",
    "        df_mlp = load_obj(path)\n",
    "    return df_mlp\n",
    "\n",
    "def select_df(df, na, selected_features, missing_values_included = False, reset_idx = True):\n",
    "    df = df.copy()\n",
    "    cols_in = set(df.columns)\n",
    "    if missing_values_included:\n",
    "        df = add_nearest_rooms_by_surface(df)\n",
    "        df = add_surface_mean_by_nearest_rooms(df)\n",
    "    else:\n",
    "        df = df.loc[:, selected_features]\n",
    "        if year_renovated in df.columns:\n",
    "            year_renovated_frame = df.loc[:, [year_renovated]]\n",
    "            df = df.drop(columns = [year_renovated])\n",
    "            df = df.dropna()\n",
    "            df[year_renovated] = year_renovated_frame.iloc[df.index, :]\n",
    "            df = handle_missing_numeric_feature(df, year_renovated, na)\n",
    "        else:\n",
    "            df = df.dropna()\n",
    "        if reset_idx:\n",
    "            df = df.reset_index(drop = True)\n",
    "    cols_out = set(df.columns)\n",
    "    add_features = list(cols_out - cols_in)\n",
    "    return df, add_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_NN(X_train, y_train, X_test, y_test, features):\n",
    "    layers, learning_rate, alpha, batch_size, max_iter, plot_error = (80,), 0.01, 0.001, 'none', 1000, True\n",
    "    mlp = MLP(layers, learning_rate = learning_rate, alpha = alpha, batch_size = batch_size, max_iter = max_iter, plot_error = plot_error)\n",
    "    X_train, y_train, X_test, y_test = X_train.to_numpy(), y_train.to_numpy().T[0], X_test.to_numpy(), y_test.to_numpy().T[0]\n",
    "    mlp.fit(X_train, y_train)\n",
    "    predicted = mlp.predict(X_test)\n",
    "        \n",
    "    m = mape(y_test, predicted)\n",
    "    residuals = y_test - predicted\n",
    "    \n",
    "    df_mlp_path = './mlp_res.pkl'\n",
    "    result = [features, layers, learning_rate, alpha, batch_size, residuals, m]\n",
    "    df_mlp = load_mlp_res(df_mlp_path)\n",
    "    series = pd.Series(result, index = df_mlp.columns)\n",
    "    df_mlp = df_mlp.append(series, ignore_index = True)\n",
    "    save_obj(df_mlp, df_mlp_path)\n",
    "    \n",
    "    mlp.store('./NN_1.pkl')\n",
    "    return df_mlp\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(layers=(80,), alpha=0.001, learning_rate=0.01)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc394a906e4b929b91debc76c83def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter', 'uid': 'b9ed746c-0691-44bc-ba7d-1d21414f0e0d', 'y': []}],\n",
       "    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num its = 990 \t\t normgrad = 2303.1697010710923 \t\t cost = 1288384485.9444222\n",
      "fit completed!\n",
      "number of iterations:  999\n",
      "max iterations:  1000\n",
      "norm(grad):  1321.2644056111449\n",
      "cost:  1194599565.1315658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>alpha</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>residuals</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[obj_type, canton, zip_code_2_digits, surface,...</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>none</td>\n",
       "      <td>[-244.48175387548167, -307.262058828574, -116....</td>\n",
       "      <td>11.849378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[obj_type, canton, zip_code_2_digits, surface,...</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>none</td>\n",
       "      <td>[-203.2536971220245, 6.011481906470408, -210.0...</td>\n",
       "      <td>11.435508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[obj_type, canton, zip_code_2_digits, surface,...</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>none</td>\n",
       "      <td>[-216.5675113669447, -159.86110521480646, -101...</td>\n",
       "      <td>11.308059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[obj_type, canton, zip_code_2_digits, surface,...</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>[-179.822233826912, -36.175313266719286, -339....</td>\n",
       "      <td>11.768765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[obj_type, canton, zip_code_2_digits, surface,...</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>[-251.0008088320269, -175.47334544745172, -296...</td>\n",
       "      <td>11.352812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[obj_type, canton, zip_code_2_digits, surface,...</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>[-212.62448131932172, 58.46136521125368, -109....</td>\n",
       "      <td>10.606158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features layers  learning_rate  \\\n",
       "0  [obj_type, canton, zip_code_2_digits, surface,...  (80,)           0.01   \n",
       "1  [obj_type, canton, zip_code_2_digits, surface,...  (80,)           0.01   \n",
       "2  [obj_type, canton, zip_code_2_digits, surface,...  (80,)           0.01   \n",
       "3  [obj_type, canton, zip_code_2_digits, surface,...  (80,)           0.01   \n",
       "4  [obj_type, canton, zip_code_2_digits, surface,...  (80,)           0.01   \n",
       "5  [obj_type, canton, zip_code_2_digits, surface,...  (80,)           0.01   \n",
       "\n",
       "   alpha batch_size                                          residuals  \\\n",
       "0  0.000       none  [-244.48175387548167, -307.262058828574, -116....   \n",
       "1  0.000       none  [-203.2536971220245, 6.011481906470408, -210.0...   \n",
       "2  0.000       none  [-216.5675113669447, -159.86110521480646, -101...   \n",
       "3  0.001       none  [-179.822233826912, -36.175313266719286, -339....   \n",
       "4  0.001       none  [-251.0008088320269, -175.47334544745172, -296...   \n",
       "5  0.001       none  [-212.62448131932172, 58.46136521125368, -109....   \n",
       "\n",
       "        MAPE  \n",
       "0  11.849378  \n",
       "1  11.435508  \n",
       "2  11.308059  \n",
       "3  11.768765  \n",
       "4  11.352812  \n",
       "5  10.606158  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init(df, na, missing_values_included = False):\n",
    "    #initialization and declaration of the variables\n",
    "    #obj_type', 'rooms', 'surface', 'zip_code_2_digits', 'canton', \n",
    "    #'year_built', 'year_renovated','distance_to_station', 'price_square_metres', 'price'\n",
    "    cat_f = [obj_type, canton, zip_code_2_digits]\n",
    "    compl_num_f = [surface, rooms, distance_to_station]\n",
    "    miss_num_f = [year_renovated, year_built]\n",
    "    targ_var = [price]\n",
    "    num_f = compl_num_f + miss_num_f\n",
    "    features = cat_f + compl_num_f + miss_num_f\n",
    "    selected_features = features + targ_var\n",
    "    \n",
    "    df, add_f = select_df(df, na, selected_features, missing_values_included)\n",
    "    df, categories = get_prepared_df(df, na, targ_var[0], cat_f, num_f, add_f, new_encoding = True)\n",
    "    df_y = df.loc[:, targ_var]\n",
    "    df_X = df.drop(targ_var, axis = 1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size = 0.25, random_state = 42)\n",
    "    df_mlp = launch_NN(X_train, y_train, X_test, y_test, features)\n",
    "    return df_mlp\n",
    "    \n",
    "init(df, na)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
